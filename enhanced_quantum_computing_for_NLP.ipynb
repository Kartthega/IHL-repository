{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kartthega/IHL-repository/blob/main/enhanced_quantum_computing_for_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantum-Inspired Feature Extraction for Sentiment Analysis\n",
        "\n",
        "Instead of using classical ML features, you embed textual sentiment features into a quantum circuit using Angle Embedding.\n",
        "Quantum embeddings are not commonly used in NLP-based sentiment classification."
      ],
      "metadata": {
        "id": "1j312g7aercn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pennylane\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqU6GPWHeNty",
        "outputId": "e61b5f1e-5636-411e-9703-4eb04b78af7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (2.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pennylane-0.40.0 pennylane-lightning-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBk4TvE-d9OG",
        "outputId": "fe821ed2-5abd-45f0-c096-bc4ed2820d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy (Quantum-Inspired): 0.9970\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a quantum-themed sentiment dataset\n",
        "def generate_quantum_sentiment_data(num_samples=1000):\n",
        "    np.random.seed(42)\n",
        "    positive_words = [\"quantum\", \"entanglement\", \"superposition\", \"qubit\", \"algorithm\", \"speedup\", \"advantage\"]\n",
        "    negative_words = [\"noise\", \"decoherence\", \"error\", \"challenge\", \"instability\", \"latency\", \"bottleneck\"]\n",
        "\n",
        "    texts, labels = [], []\n",
        "    for _ in range(num_samples):\n",
        "        words = np.random.choice(positive_words + negative_words, size=np.random.randint(5, 15))\n",
        "        text = \" \".join(words)\n",
        "        label = 1 if sum(w in positive_words for w in words) > sum(w in negative_words for w in words) else 0\n",
        "        texts.append(text)\n",
        "        labels.append(label)\n",
        "\n",
        "    return texts, np.array(labels)\n",
        "\n",
        "# Convert text into numerical features\n",
        "def text_to_features(texts, positive_words, negative_words):\n",
        "    features = []\n",
        "    for text in texts:\n",
        "        positive_count = sum(word in positive_words for word in text.split())\n",
        "        negative_count = sum(word in negative_words for word in text.split())\n",
        "        features.append([positive_count, negative_count])\n",
        "    return np.array(features)\n",
        "\n",
        "# Define quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=2, shots=1024)\n",
        "\n",
        "# Quantum feature extraction function\n",
        "@qml.qnode(dev)\n",
        "def quantum_embedding(inputs):\n",
        "    qml.AngleEmbedding(inputs, wires=[0, 1])\n",
        "    return qml.probs(wires=[0, 1])\n",
        "\n",
        "# Classifier using nearest-neighbor approach\n",
        "def quantum_nearest_neighbor(train_features, train_labels, test_features):\n",
        "    train_embeddings = np.array([quantum_embedding(f) for f in train_features])\n",
        "    test_embeddings = np.array([quantum_embedding(f) for f in test_features])\n",
        "\n",
        "    def classify(test_emb):\n",
        "        distances = [np.linalg.norm(test_emb - emb) for emb in train_embeddings]\n",
        "        return train_labels[np.argmin(distances)]\n",
        "\n",
        "    return np.array([classify(te) for te in test_embeddings])\n",
        "\n",
        "# Main execution\n",
        "texts, labels = generate_quantum_sentiment_data()\n",
        "positive_words = [\"quantum\", \"entanglement\", \"superposition\", \"qubit\", \"algorithm\", \"speedup\", \"advantage\"]\n",
        "negative_words = [\"noise\", \"decoherence\", \"error\", \"challenge\", \"instability\", \"latency\", \"bottleneck\"]\n",
        "\n",
        "features = text_to_features(texts, positive_words, negative_words)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_predictions = quantum_nearest_neighbor(train_features, train_labels, train_features)\n",
        "test_predictions = quantum_nearest_neighbor(train_features, train_labels, test_features)\n",
        "\n",
        "overall_predictions = np.concatenate((train_predictions, test_predictions))\n",
        "overall_labels = np.concatenate((train_labels, test_labels))\n",
        "\n",
        "overall_accuracy = np.mean(overall_predictions == overall_labels)\n",
        "print(f\"Overall Accuracy (Quantum-Inspired): {overall_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hybrid Quantum-Classical Nearest Neighbor Classifier\n",
        "\n",
        "Instead of training a variational quantum circuit (VQC), you use a distance-based classifier on quantum-generated embeddings.\n",
        "This is an alternative quantum approach to supervised learning, different from traditional VQCs or quantum kernels.\n"
      ],
      "metadata": {
        "id": "tQuwE2Freuzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a dataset for sentiment analysis\n",
        "def generate_quantum_sentiment_data(num_samples=1000):\n",
        "    np.random.seed(42)\n",
        "    positive_words = [\"quantum\", \"entanglement\", \"superposition\", \"qubit\", \"algorithm\", \"speedup\", \"advantage\"]\n",
        "    negative_words = [\"noise\", \"decoherence\", \"error\", \"challenge\", \"instability\", \"latency\", \"bottleneck\"]\n",
        "\n",
        "    texts, labels = [], []\n",
        "    for _ in range(num_samples):\n",
        "        words = np.random.choice(positive_words + negative_words, size=np.random.randint(5, 15))\n",
        "        text = \" \".join(words)\n",
        "        label = 1 if sum(w in positive_words for w in words) > sum(w in negative_words for w in words) else 0\n",
        "        texts.append(text)\n",
        "        labels.append(label)\n",
        "\n",
        "    return texts, np.array(labels)\n",
        "\n",
        "# Convert text into numerical features\n",
        "def text_to_features(texts, positive_words, negative_words):\n",
        "    features = []\n",
        "    for text in texts:\n",
        "        positive_count = sum(word in positive_words for word in text.split())\n",
        "        negative_count = sum(word in negative_words for word in text.split())\n",
        "        features.append([positive_count, negative_count])\n",
        "    return np.array(features)\n",
        "\n",
        "# Define quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=2, shots=1024)\n",
        "\n",
        "# Quantum feature embedding function\n",
        "@qml.qnode(dev)\n",
        "def quantum_embedding(inputs):\n",
        "    qml.AngleEmbedding(inputs, wires=[0, 1])\n",
        "    return qml.probs(wires=[0, 1])\n",
        "\n",
        "# Hybrid Quantum-Classical Nearest Neighbor Classifier\n",
        "def hybrid_qc_knn(train_features, train_labels, test_features):\n",
        "    train_embeddings = np.array([quantum_embedding(f) for f in train_features])\n",
        "    test_embeddings = np.array([quantum_embedding(f) for f in test_features])\n",
        "\n",
        "    def classify(test_emb):\n",
        "        distances = [np.linalg.norm(test_emb - emb) for emb in train_embeddings]\n",
        "        return train_labels[np.argmin(distances)]\n",
        "\n",
        "    return np.array([classify(te) for te in test_embeddings])\n",
        "\n",
        "# Main execution\n",
        "texts, labels = generate_quantum_sentiment_data()\n",
        "positive_words = [\"quantum\", \"entanglement\", \"superposition\", \"qubit\", \"algorithm\", \"speedup\", \"advantage\"]\n",
        "negative_words = [\"noise\", \"decoherence\", \"error\", \"challenge\", \"instability\", \"latency\", \"bottleneck\"]\n",
        "\n",
        "features = text_to_features(texts, positive_words, negative_words)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_predictions = hybrid_qc_knn(train_features, train_labels, train_features)\n",
        "test_predictions = hybrid_qc_knn(train_features, train_labels, test_features)\n",
        "\n",
        "overall_predictions = np.concatenate((train_predictions, test_predictions))\n",
        "overall_labels = np.concatenate((train_labels, test_labels))\n",
        "\n",
        "overall_accuracy = np.mean(overall_predictions == overall_labels)\n",
        "print(f\"Overall Accuracy (Hybrid Quantum-Classical KNN): {overall_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gLQWcsYfbZR",
        "outputId": "c008fe0e-f351-45fc-897e-d3a67a665af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy (Hybrid Quantum-Classical KNN): 0.9960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application to Quantum Texts\n",
        "\n",
        "Many NLP models focus on general sentiment analysis, but your model specializes in sentiment detection in quantum computing discussions.\n",
        "This is a unique application, which could be useful in fields like scientific document analysis"
      ],
      "metadata": {
        "id": "_2yDGYhNf9M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate dataset specialized in quantum computing discussions\n",
        "def generate_quantum_text_data(num_samples=1000):\n",
        "    np.random.seed(42)\n",
        "    positive_words = [\"quantum\", \"entanglement\", \"superposition\", \"qubit\", \"algorithm\", \"speedup\", \"advantage\", \"coherence\", \"stability\"]\n",
        "    negative_words = [\"noise\", \"decoherence\", \"error\", \"challenge\", \"instability\", \"latency\", \"bottleneck\", \"fragile\", \"scalability\"]\n",
        "\n",
        "    texts, labels = [], []\n",
        "    for _ in range(num_samples):\n",
        "        words = np.random.choice(positive_words + negative_words, size=np.random.randint(5, 15))\n",
        "        text = \" \".join(words)\n",
        "        label = 1 if sum(w in positive_words for w in words) > sum(w in negative_words for w in words) else 0\n",
        "        texts.append(text)\n",
        "        labels.append(label)\n",
        "\n",
        "    return texts, np.array(labels)\n",
        "\n",
        "# Convert text into numerical sentiment features\n",
        "def text_to_features(texts, positive_words, negative_words):\n",
        "    features = []\n",
        "    for text in texts:\n",
        "        positive_count = sum(word in positive_words for word in text.split())\n",
        "        negative_count = sum(word in negative_words for word in text.split())\n",
        "        features.append([positive_count, negative_count])\n",
        "    return np.array(features)\n",
        "\n",
        "# Define quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=2, shots=1024)\n",
        "\n",
        "# Quantum feature embedding function\n",
        "@qml.qnode(dev)\n",
        "def quantum_embedding(inputs):\n",
        "    qml.AngleEmbedding(inputs, wires=[0, 1])\n",
        "    return qml.probs(wires=[0, 1])\n",
        "\n",
        "# Quantum-Classical Nearest Neighbor Classifier\n",
        "def quantum_text_sentiment(train_features, train_labels, test_features):\n",
        "    train_embeddings = np.array([quantum_embedding(f) for f in train_features])\n",
        "    test_embeddings = np.array([quantum_embedding(f) for f in test_features])\n",
        "\n",
        "    def classify(test_emb):\n",
        "        distances = [np.linalg.norm(test_emb - emb) for emb in train_embeddings]\n",
        "        return train_labels[np.argmin(distances)]\n",
        "\n",
        "    return np.array([classify(te) for te in test_embeddings])\n",
        "\n",
        "# Main execution\n",
        "texts, labels = generate_quantum_text_data()\n",
        "positive_words = [\"quantum\", \"entanglement\", \"superposition\", \"qubit\", \"algorithm\", \"speedup\", \"advantage\", \"coherence\", \"stability\"]\n",
        "negative_words = [\"noise\", \"decoherence\", \"error\", \"challenge\", \"instability\", \"latency\", \"bottleneck\", \"fragile\", \"scalability\"]\n",
        "\n",
        "features = text_to_features(texts, positive_words, negative_words)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_predictions = quantum_text_sentiment(train_features, train_labels, train_features)\n",
        "test_predictions = quantum_text_sentiment(train_features, train_labels, test_features)\n",
        "\n",
        "overall_predictions = np.concatenate((train_predictions, test_predictions))\n",
        "overall_labels = np.concatenate((train_labels, test_labels))\n",
        "\n",
        "overall_accuracy = np.mean(overall_predictions == overall_labels)\n",
        "print(f\"Overall Accuracy (Quantum Text Sentiment): {overall_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_fu5Lbjf8ht",
        "outputId": "ec7147a7-5573-4cfa-a2b1-d38d64545748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy (Quantum Text Sentiment): 0.9980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1st model in this again with complex dataset"
      ],
      "metadata": {
        "id": "xU2639VAhL__"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JkzF0zTOjkLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm used in the code can be described as a Quantum-Inspired Nearest Neighbor Classifier for Sentiment Analysis.\n",
        "\n",
        "In summary, the algorithm uses a classical nearest neighbor approach but leverages a quantum circuit for feature embedding. While the individual components are known, the specific combination and application, especially with a focus on quantum-inspired feature representations, contribute to its nature as a quantum-inspired algorithm. Whether it's \"novel\" in a groundbreaking sense depends on the specific implementation details and the context of its application compared to existing work in quantum and classical machine learning.\n",
        "\n",
        "Quantum Circuit for Feature Embedding: The code does use a quantum circuit (defined using PennyLane and run on a simulator) to create a representation of the classical features. This is the \"quantum\" part.\n",
        "\n",
        "Classical Nearest Neighbor: The core classification logic of finding the nearest neighbor based on Euclidean distance is a purely classical algorithm.\n",
        "\n",
        "Simulation: The quantum circuit is being run on a classical simulator (default.qubit in PennyLane). It's not being executed on actual quantum hardware\n",
        "\n"
      ],
      "metadata": {
        "id": "pD91cEluHhux"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89df5419-ec74-4807-dfdb-3938e3d9ca89",
        "id": "Q83Azwmwjkwc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy (Quantum-Inspired): 0.9710\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a quantum-themed sentiment dataset\n",
        "def generate_quantum_sentiment_data(num_samples=1000):\n",
        "    np.random.seed(42)\n",
        "    positive_words = [\n",
        "    \"quantum\", \"entanglement\", \"superposition\", \"qubit\", \"algorithm\", \"speedup\", \"advantage\",\n",
        "    \"innovation\", \"discovery\", \"breakthrough\", \"achievement\", \"progress\", \"excellence\", \"success\",\n",
        "    \"efficiency\", \"accuracy\", \"optimization\", \"enhancement\", \"growth\", \"improvement\", \"advancement\",\n",
        "    \"solution\", \"precision\", \"stability\", \"reliability\", \"performance\", \"potential\", \"capability\",\n",
        "    \"creativity\", \"vision\", \"brilliance\", \"mastery\", \"wisdom\", \"insight\", \"understanding\", \"clarity\",\n",
        "    \"elegance\", \"simplicity\", \"effectiveness\", \"harmony\", \"balance\", \"cohesion\", \"synergy\", \"integration\",\n",
        "    \"collaboration\", \"teamwork\", \"partnership\", \"unity\", \"trust\", \"support\", \"encouragement\", \"inspiration\",\n",
        "    \"motivation\", \"dedication\", \"commitment\", \"determination\", \"perseverance\", \"resilience\", \"tenacity\",\n",
        "    \"courage\", \"boldness\", \"fearlessness\", \"confidence\", \"self-belief\", \"empowerment\", \"independence\",\n",
        "    \"freedom\", \"autonomy\", \"initiative\", \"leadership\", \"strategy\", \"foresight\", \"planning\", \"organization\",\n",
        "    \"execution\", \"action\", \"momentum\", \"acceleration\", \"drive\", \"ambition\", \"aspiration\", \"dream\",\n",
        "    \"visionary\", \"futuristic\", \"modernization\", \"revolution\", \"transformation\", \"evolution\", \"progression\",\n",
        "    \"breakthrough\", \"discovery\", \"innovation\", \"invention\", \"originality\", \"creativity\", \"genius\", \"talent\",\n",
        "    \"skill\", \"expertise\", \"competence\", \"proficiency\", \"specialization\", \"mastery\", \"brilliance\", \"ingenuity\",\n",
        "    \"intelligence\", \"smartness\", \"sharpness\", \"quick-wittedness\", \"resourcefulness\", \"adaptability\", \"flexibility\",\n",
        "    \"open-mindedness\", \"curiosity\", \"exploration\", \"investigation\", \"research\", \"analysis\", \"examination\",\n",
        "    \"understanding\", \"comprehension\", \"insight\", \"awareness\", \"enlightenment\", \"wisdom\", \"knowledge\",\n",
        "    \"education\", \"learning\", \"studies\", \"growth\", \"self-improvement\", \"development\", \"enhancement\",\n",
        "    \"progress\", \"expansion\", \"advancement\", \"enrichment\", \"refinement\", \"polish\", \"perfection\", \"excellence\",\n",
        "    \"superiority\", \"outperformance\", \"effectiveness\", \"efficiency\", \"optimization\", \"streamlining\",\n",
        "    \"refinement\", \"precision\", \"accuracy\", \"consistency\", \"predictability\", \"stability\", \"reliability\",\n",
        "    \"durability\", \"longevity\", \"sustainability\", \"environmentally-friendly\", \"eco-friendly\", \"green\",\n",
        "    \"conservation\", \"preservation\", \"innovation\", \"modernization\", \"digitalization\", \"automation\",\n",
        "    \"robotics\", \"artificial intelligence\", \"machine learning\", \"deep learning\", \"neural networks\",\n",
        "    \"data science\", \"big data\", \"analytics\", \"cybersecurity\", \"encryption\", \"privacy\", \"blockchain\",\n",
        "    \"smart contracts\", \"cryptography\", \"secure computing\", \"quantum cryptography\", \"quantum computing\",\n",
        "    \"cloud computing\", \"distributed systems\", \"networking\", \"connectivity\", \"internet of things\",\n",
        "    \"wireless technology\", \"5G\", \"high-speed\", \"fast\", \"effortless\", \"seamless\", \"intuitive\", \"user-friendly\",\n",
        "    \"ergonomic\", \"accessible\", \"inclusive\", \"diverse\", \"multicultural\", \"global\", \"universal\", \"comprehensive\",\n",
        "    \"holistic\", \"integrated\", \"coordinated\", \"synchronized\", \"structured\", \"organized\", \"methodical\",\n",
        "    \"systematic\", \"strategic\", \"tactical\", \"calculated\", \"deliberate\", \"purposeful\", \"meaningful\", \"impactful\",\n",
        "    \"transformative\", \"revolutionary\", \"game-changing\", \"groundbreaking\", \"pioneering\", \"trailblazing\",\n",
        "    \"visionary\", \"inspirational\", \"motivational\", \"empowering\", \"uplifting\", \"positive\", \"optimistic\",\n",
        "    \"hopeful\", \"encouraging\", \"supportive\", \"nurturing\", \"compassionate\", \"kind\", \"generous\", \"altruistic\",\n",
        "    \"selfless\", \"thoughtful\", \"considerate\", \"helpful\", \"benevolent\", \"charitable\", \"philanthropic\",\n",
        "    \"community-driven\", \"service-oriented\", \"customer-focused\", \"client-centric\", \"user-experience\",\n",
        "    \"human-centered\", \"ethical\", \"moral\", \"responsible\", \"accountable\", \"trustworthy\", \"reliable\",\n",
        "    \"dependable\", \"honest\", \"transparent\", \"fair\", \"just\", \"equitable\", \"inclusive\", \"diverse\", \"respectful\",\n",
        "    \"courteous\", \"polite\", \"gracious\", \"humble\", \"modest\", \"down-to-earth\", \"genuine\", \"authentic\",\n",
        "    \"real\", \"sincere\", \"wholehearted\", \"passionate\", \"enthusiastic\", \"energetic\", \"lively\", \"vibrant\",\n",
        "    \"dynamic\", \"versatile\", \"multi-talented\", \"well-rounded\", \"balanced\", \"harmonious\", \"peaceful\",\n",
        "    \"calm\", \"serene\", \"tranquil\", \"relaxed\", \"mindful\", \"thoughtful\", \"reflective\", \"philosophical\",\n",
        "    \"deep-thinking\", \"introspective\", \"contemplative\", \"meditative\", \"self-aware\", \"emotionally-intelligent\",\n",
        "    \"empathetic\", \"understanding\", \"forgiving\", \"patient\", \"tolerant\", \"accepting\", \"open-minded\",\n",
        "    \"flexible\", \"adaptive\", \"resilient\", \"strong\", \"hardy\", \"tough\", \"tenacious\", \"persistent\",\n",
        "    \"dedicated\", \"committed\", \"focused\", \"determined\", \"goal-oriented\", \"ambitious\", \"driven\",\n",
        "    \"hardworking\", \"diligent\", \"industrious\", \"productive\", \"efficient\", \"organized\", \"methodical\",\n",
        "    \"systematic\", \"orderly\", \"neat\", \"tidy\", \"clean\", \"structured\", \"disciplined\", \"responsible\",\n",
        "    \"conscientious\", \"ethical\", \"honorable\", \"principled\", \"trustworthy\", \"loyal\", \"faithful\",\n",
        "    \"devoted\", \"affectionate\", \"loving\", \"caring\", \"kind-hearted\", \"warm\", \"friendly\", \"sociable\",\n",
        "    \"outgoing\", \"charismatic\", \"magnetic\", \"influential\", \"persuasive\", \"convincing\", \"eloquent\",\n",
        "    \"articulate\", \"well-spoken\", \"expressive\", \"creative\", \"imaginative\", \"innovative\", \"resourceful\",\n",
        "    \"clever\", \"intelligent\", \"wise\", \"insightful\", \"perceptive\", \"astute\", \"sharp\", \"keen\", \"observant\",\n",
        "    \"attentive\", \"aware\", \"mindful\", \"thoughtful\", \"caring\", \"considerate\", \"sensitive\", \"compassionate\",\n",
        "    \"supportive\", \"nurturing\", \"helpful\", \"benevolent\", \"generous\", \"selfless\", \"charitable\", \"giving\",\n",
        "    \"philanthropic\", \"humble\", \"modest\", \"gracious\", \"grateful\", \"appreciative\", \"thankful\", \"positive\",\n",
        "    \"optimistic\", \"hopeful\", \"cheerful\", \"joyful\", \"happy\", \"content\", \"peaceful\", \"calm\", \"serene\",\n",
        "    \"harmonious\", \"balanced\", \"grounded\", \"strong\", \"resilient\", \"fearless\", \"bold\", \"brave\", \"courageous\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "    negative_words = [\n",
        "    \"failure\", \"error\", \"challenge\", \"instability\", \"latency\", \"bottleneck\", \"weakness\", \"limitation\",\n",
        "    \"flaw\", \"inefficiency\", \"delay\", \"obstacle\", \"hindrance\", \"drawback\", \"shortcoming\", \"defect\", \"glitch\",\n",
        "    \"malfunction\", \"miscalculation\", \"misalignment\", \"breakdown\", \"interruption\", \"disruption\", \"inconsistency\",\n",
        "    \"dissonance\", \"complication\", \"complexity\", \"overhead\", \"redundancy\", \"regression\", \"deterioration\",\n",
        "    \"degradation\", \"decay\", \"erosion\", \"corruption\", \"contamination\", \"pollution\", \"spillage\", \"overload\",\n",
        "    \"exhaustion\", \"depletion\", \"scarcity\", \"insufficiency\", \"lack\", \"absence\", \"deficit\", \"shortage\",\n",
        "    \"defectiveness\", \"fault\", \"imperfection\", \"vulnerability\", \"fragility\", \"breakability\", \"insecurity\",\n",
        "    \"exposure\", \"risk\", \"hazard\", \"danger\", \"peril\", \"threat\", \"jeopardy\", \"pitfall\", \"trap\", \"setback\",\n",
        "    \"problem\", \"difficulty\", \"concern\", \"worry\", \"anxiety\", \"stress\", \"tension\", \"pressure\", \"strain\",\n",
        "    \"burden\", \"weight\", \"load\", \"fatigue\", \"exhaustion\", \"weariness\", \"burnout\", \"discomfort\", \"pain\",\n",
        "    \"agony\", \"suffering\", \"misery\", \"torment\", \"distress\", \"affliction\", \"trouble\", \"crisis\", \"catastrophe\",\n",
        "    \"disaster\", \"calamity\", \"tragedy\", \"devastation\", \"chaos\", \"turmoil\", \"havoc\", \"pandemonium\", \"disarray\",\n",
        "    \"confusion\", \"disorganization\", \"disorder\", \"mess\", \"clutter\", \"complication\", \"misunderstanding\",\n",
        "    \"miscommunication\", \"misinterpretation\", \"conflict\", \"disagreement\", \"dispute\", \"argument\", \"quarrel\",\n",
        "    \"fight\", \"hostility\", \"resentment\", \"bitterness\", \"anger\", \"rage\", \"fury\", \"outrage\", \"wrath\", \"hatred\",\n",
        "    \"animosity\", \"antagonism\", \"loathing\", \"disgust\", \"repulsion\", \"revulsion\", \"negativity\", \"pessimism\",\n",
        "    \"cynicism\", \"skepticism\", \"doubt\", \"uncertainty\", \"apprehension\", \"fear\", \"dread\", \"terror\", \"horror\",\n",
        "    \"paranoia\", \"shock\", \"surprise\", \"unpleasantness\", \"offense\", \"insult\", \"humiliation\", \"shame\",\n",
        "    \"embarrassment\", \"awkwardness\", \"guilt\", \"remorse\", \"regret\", \"disappointment\", \"frustration\",\n",
        "    \"exasperation\", \"displeasure\", \"dissatisfaction\", \"discontent\", \"envy\", \"jealousy\", \"greed\", \"selfishness\",\n",
        "    \"arrogance\", \"pride\", \"egotism\", \"narcissism\", \"vanity\", \"superiority\", \"condescension\", \"rudeness\",\n",
        "    \"disrespect\", \"insensitivity\", \"inconsideration\", \"carelessness\", \"negligence\", \"recklessness\",\n",
        "    \"irresponsibility\", \"indifference\", \"apathy\", \"coldness\", \"harshness\", \"cruelty\", \"violence\", \"aggression\",\n",
        "    \"brutality\", \"oppression\", \"exploitation\", \"manipulation\", \"deception\", \"dishonesty\", \"betrayal\", \"fraud\",\n",
        "    \"corruption\", \"scandal\", \"crime\", \"theft\", \"robbery\", \"violence\", \"assault\", \"murder\", \"homicide\", \"abuse\",\n",
        "    \"harassment\", \"bullying\", \"discrimination\", \"prejudice\", \"bigotry\", \"injustice\", \"inequality\", \"suppression\",\n",
        "    \"censorship\", \"dictatorship\", \"tyranny\", \"war\", \"battle\", \"invasion\", \"occupation\", \"subjugation\", \"enslavement\",\n",
        "    \"poverty\", \"homelessness\", \"starvation\", \"malnutrition\", \"sickness\", \"disease\", \"illness\", \"infection\",\n",
        "    \"epidemic\", \"pandemic\", \"injury\", \"wound\", \"disability\", \"handicap\", \"impairment\", \"aging\", \"decline\",\n",
        "    \"depression\", \"melancholy\", \"sadness\", \"grief\", \"mourning\", \"loss\", \"loneliness\", \"isolation\", \"alienation\",\n",
        "    \"rejection\", \"abandonment\", \"neglect\", \"despair\", \"hopelessness\", \"worthlessness\", \"uselessness\",\n",
        "    \"destruction\", \"wreckage\", \"damage\", \"harm\", \"suffering\", \"torture\", \"persecution\", \"mercilessness\",\n",
        "    \"unfairness\", \"bias\", \"segregation\", \"marginalization\", \"foolishness\", \"ignorance\", \"stupidity\",\n",
        "    \"incompetence\", \"ineptitude\", \"clumsiness\", \"misfortune\", \"bad luck\", \"curse\", \"doom\", \"futility\",\n",
        "    \"pointlessness\", \"meaninglessness\", \"emptiness\", \"anguish\", \"shock\", \"delusion\", \"nightmare\", \"drowning\",\n",
        "    \"drowning\", \"meltdown\", \"breakup\", \"ruin\", \"bankruptcy\", \"infestation\", \"parasite\", \"disgusting\",\n",
        "    \"obnoxious\", \"worthless\", \"useless\", \"insignificant\", \"unimportant\", \"fail\", \"fallacy\", \"rumor\",\n",
        "    \"depressed\", \"broken\", \"ruined\", \"hopeless\", \"wretched\", \"shattered\", \"blasted\", \"poison\", \"backstabbed\",\n",
        "    \"betrayed\", \"downfall\", \"crumbling\", \"abomination\", \"awful\", \"horrible\", \"dismal\", \"deplorable\", \"disgrace\",\n",
        "    \"disgust\", \"dire\", \"bleak\", \"desperate\", \"failing\", \"troublemaker\", \"villain\", \"cheater\", \"usurper\",\n",
        "    \"liar\", \"thief\", \"miscreant\", \"scoundrel\", \"crook\", \"tyrant\", \"traitor\", \"fraudster\", \"embezzler\",\n",
        "    \"backstabber\", \"charlatan\", \"manipulator\", \"exploiter\", \"phony\", \"deceiver\", \"two-faced\", \"schemer\",\n",
        "    \"dishonorable\", \"unethical\", \"immoral\", \"sinister\", \"malicious\", \"nefarious\", \"vicious\", \"corrupt\",\n",
        "    \"insidious\", \"depraved\", \"diabolical\", \"malevolent\", \"villainous\", \"atrocious\", \"abysmal\", \"barbaric\",\n",
        "    \"heinous\", \"ghastly\", \"gruesome\", \"nightmarish\", \"demonic\", \"satanic\", \"fiendish\", \"morbid\", \"grisly\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    texts, labels = [], []\n",
        "    for _ in range(num_samples):\n",
        "        words = np.random.choice(positive_words + negative_words, size=np.random.randint(5, 15))\n",
        "        text = \" \".join(words)\n",
        "        label = 1 if sum(w in positive_words for w in words) > sum(w in negative_words for w in words) else 0\n",
        "        texts.append(text)\n",
        "        labels.append(label)\n",
        "\n",
        "    return texts, np.array(labels)\n",
        "\n",
        "# Convert text into numerical features\n",
        "def text_to_features(texts, positive_words, negative_words):\n",
        "    features = []\n",
        "    for text in texts:\n",
        "        positive_count = sum(word in positive_words for word in text.split())\n",
        "        negative_count = sum(word in negative_words for word in text.split())\n",
        "        features.append([positive_count, negative_count])\n",
        "    return np.array(features)\n",
        "\n",
        "# Define quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=2, shots=1024)\n",
        "\n",
        "# Quantum feature extraction function\n",
        "@qml.qnode(dev)\n",
        "def quantum_embedding(inputs):\n",
        "    qml.AngleEmbedding(inputs, wires=[0, 1])\n",
        "    return qml.probs(wires=[0, 1])\n",
        "\n",
        "# Classifier using nearest-neighbor approach\n",
        "def quantum_nearest_neighbor(train_features, train_labels, test_features):\n",
        "    train_embeddings = np.array([quantum_embedding(f) for f in train_features])\n",
        "    test_embeddings = np.array([quantum_embedding(f) for f in test_features])\n",
        "\n",
        "    def classify(test_emb):\n",
        "        distances = [np.linalg.norm(test_emb - emb) for emb in train_embeddings]\n",
        "        return train_labels[np.argmin(distances)]\n",
        "\n",
        "    return np.array([classify(te) for te in test_embeddings])\n",
        "\n",
        "# Main execution\n",
        "texts, labels = generate_quantum_sentiment_data()\n",
        "positive_words = [\n",
        "    \"quantum\", \"entanglement\", \"superposition\", \"qubit\", \"algorithm\", \"speedup\", \"advantage\",\n",
        "    \"innovation\", \"discovery\", \"breakthrough\", \"achievement\", \"progress\", \"excellence\", \"success\",\n",
        "    \"efficiency\", \"accuracy\", \"optimization\", \"enhancement\", \"growth\", \"improvement\", \"advancement\",\n",
        "    \"solution\", \"precision\", \"stability\", \"reliability\", \"performance\", \"potential\", \"capability\",\n",
        "    \"creativity\", \"vision\", \"brilliance\", \"mastery\", \"wisdom\", \"insight\", \"understanding\", \"clarity\",\n",
        "    \"elegance\", \"simplicity\", \"effectiveness\", \"harmony\", \"balance\", \"cohesion\", \"synergy\", \"integration\",\n",
        "    \"collaboration\", \"teamwork\", \"partnership\", \"unity\", \"trust\", \"support\", \"encouragement\", \"inspiration\",\n",
        "    \"motivation\", \"dedication\", \"commitment\", \"determination\", \"perseverance\", \"resilience\", \"tenacity\",\n",
        "    \"courage\", \"boldness\", \"fearlessness\", \"confidence\", \"self-belief\", \"empowerment\", \"independence\",\n",
        "    \"freedom\", \"autonomy\", \"initiative\", \"leadership\", \"strategy\", \"foresight\", \"planning\", \"organization\",\n",
        "    \"execution\", \"action\", \"momentum\", \"acceleration\", \"drive\", \"ambition\", \"aspiration\", \"dream\",\n",
        "    \"visionary\", \"futuristic\", \"modernization\", \"revolution\", \"transformation\", \"evolution\", \"progression\",\n",
        "    \"breakthrough\", \"discovery\", \"innovation\", \"invention\", \"originality\", \"creativity\", \"genius\", \"talent\",\n",
        "    \"skill\", \"expertise\", \"competence\", \"proficiency\", \"specialization\", \"mastery\", \"brilliance\", \"ingenuity\",\n",
        "    \"intelligence\", \"smartness\", \"sharpness\", \"quick-wittedness\", \"resourcefulness\", \"adaptability\", \"flexibility\",\n",
        "    \"open-mindedness\", \"curiosity\", \"exploration\", \"investigation\", \"research\", \"analysis\", \"examination\",\n",
        "    \"understanding\", \"comprehension\", \"insight\", \"awareness\", \"enlightenment\", \"wisdom\", \"knowledge\",\n",
        "    \"education\", \"learning\", \"studies\", \"growth\", \"self-improvement\", \"development\", \"enhancement\",\n",
        "    \"progress\", \"expansion\", \"advancement\", \"enrichment\", \"refinement\", \"polish\", \"perfection\", \"excellence\",\n",
        "    \"superiority\", \"outperformance\", \"effectiveness\", \"efficiency\", \"optimization\", \"streamlining\",\n",
        "    \"refinement\", \"precision\", \"accuracy\", \"consistency\", \"predictability\", \"stability\", \"reliability\",\n",
        "    \"durability\", \"longevity\", \"sustainability\", \"environmentally-friendly\", \"eco-friendly\", \"green\",\n",
        "    \"conservation\", \"preservation\", \"innovation\", \"modernization\", \"digitalization\", \"automation\",\n",
        "    \"robotics\", \"artificial intelligence\", \"machine learning\", \"deep learning\", \"neural networks\",\n",
        "    \"data science\", \"big data\", \"analytics\", \"cybersecurity\", \"encryption\", \"privacy\", \"blockchain\",\n",
        "    \"smart contracts\", \"cryptography\", \"secure computing\", \"quantum cryptography\", \"quantum computing\",\n",
        "    \"cloud computing\", \"distributed systems\", \"networking\", \"connectivity\", \"internet of things\",\n",
        "    \"wireless technology\", \"5G\", \"high-speed\", \"fast\", \"effortless\", \"seamless\", \"intuitive\", \"user-friendly\",\n",
        "    \"ergonomic\", \"accessible\", \"inclusive\", \"diverse\", \"multicultural\", \"global\", \"universal\", \"comprehensive\",\n",
        "    \"holistic\", \"integrated\", \"coordinated\", \"synchronized\", \"structured\", \"organized\", \"methodical\",\n",
        "    \"systematic\", \"strategic\", \"tactical\", \"calculated\", \"deliberate\", \"purposeful\", \"meaningful\", \"impactful\",\n",
        "    \"transformative\", \"revolutionary\", \"game-changing\", \"groundbreaking\", \"pioneering\", \"trailblazing\",\n",
        "    \"visionary\", \"inspirational\", \"motivational\", \"empowering\", \"uplifting\", \"positive\", \"optimistic\",\n",
        "    \"hopeful\", \"encouraging\", \"supportive\", \"nurturing\", \"compassionate\", \"kind\", \"generous\", \"altruistic\",\n",
        "    \"selfless\", \"thoughtful\", \"considerate\", \"helpful\", \"benevolent\", \"charitable\", \"philanthropic\",\n",
        "    \"community-driven\", \"service-oriented\", \"customer-focused\", \"client-centric\", \"user-experience\",\n",
        "    \"human-centered\", \"ethical\", \"moral\", \"responsible\", \"accountable\", \"trustworthy\", \"reliable\",\n",
        "    \"dependable\", \"honest\", \"transparent\", \"fair\", \"just\", \"equitable\", \"inclusive\", \"diverse\", \"respectful\",\n",
        "    \"courteous\", \"polite\", \"gracious\", \"humble\", \"modest\", \"down-to-earth\", \"genuine\", \"authentic\",\n",
        "    \"real\", \"sincere\", \"wholehearted\", \"passionate\", \"enthusiastic\", \"energetic\", \"lively\", \"vibrant\",\n",
        "    \"dynamic\", \"versatile\", \"multi-talented\", \"well-rounded\", \"balanced\", \"harmonious\", \"peaceful\",\n",
        "    \"calm\", \"serene\", \"tranquil\", \"relaxed\", \"mindful\", \"thoughtful\", \"reflective\", \"philosophical\",\n",
        "    \"deep-thinking\", \"introspective\", \"contemplative\", \"meditative\", \"self-aware\", \"emotionally-intelligent\",\n",
        "    \"empathetic\", \"understanding\", \"forgiving\", \"patient\", \"tolerant\", \"accepting\", \"open-minded\",\n",
        "    \"flexible\", \"adaptive\", \"resilient\", \"strong\", \"hardy\", \"tough\", \"tenacious\", \"persistent\",\n",
        "    \"dedicated\", \"committed\", \"focused\", \"determined\", \"goal-oriented\", \"ambitious\", \"driven\",\n",
        "    \"hardworking\", \"diligent\", \"industrious\", \"productive\", \"efficient\", \"organized\", \"methodical\",\n",
        "    \"systematic\", \"orderly\", \"neat\", \"tidy\", \"clean\", \"structured\", \"disciplined\", \"responsible\",\n",
        "    \"conscientious\", \"ethical\", \"honorable\", \"principled\", \"trustworthy\", \"loyal\", \"faithful\",\n",
        "    \"devoted\", \"affectionate\", \"loving\", \"caring\", \"kind-hearted\", \"warm\", \"friendly\", \"sociable\",\n",
        "    \"outgoing\", \"charismatic\", \"magnetic\", \"influential\", \"persuasive\", \"convincing\", \"eloquent\",\n",
        "    \"articulate\", \"well-spoken\", \"expressive\", \"creative\", \"imaginative\", \"innovative\", \"resourceful\",\n",
        "    \"clever\", \"intelligent\", \"wise\", \"insightful\", \"perceptive\", \"astute\", \"sharp\", \"keen\", \"observant\",\n",
        "    \"attentive\", \"aware\", \"mindful\", \"thoughtful\", \"caring\", \"considerate\", \"sensitive\", \"compassionate\",\n",
        "    \"supportive\", \"nurturing\", \"helpful\", \"benevolent\", \"generous\", \"selfless\", \"charitable\", \"giving\",\n",
        "    \"philanthropic\", \"humble\", \"modest\", \"gracious\", \"grateful\", \"appreciative\", \"thankful\", \"positive\",\n",
        "    \"optimistic\", \"hopeful\", \"cheerful\", \"joyful\", \"happy\", \"content\", \"peaceful\", \"calm\", \"serene\",\n",
        "    \"harmonious\", \"balanced\", \"grounded\", \"strong\", \"resilient\", \"fearless\", \"bold\", \"brave\", \"courageous\"\n",
        "]\n",
        "\n",
        "negative_words = [\n",
        "    \"failure\", \"error\", \"challenge\", \"instability\", \"latency\", \"bottleneck\", \"weakness\", \"limitation\",\n",
        "    \"flaw\", \"inefficiency\", \"delay\", \"obstacle\", \"hindrance\", \"drawback\", \"shortcoming\", \"defect\", \"glitch\",\n",
        "    \"malfunction\", \"miscalculation\", \"misalignment\", \"breakdown\", \"interruption\", \"disruption\", \"inconsistency\",\n",
        "    \"dissonance\", \"complication\", \"complexity\", \"overhead\", \"redundancy\", \"regression\", \"deterioration\",\n",
        "    \"degradation\", \"decay\", \"erosion\", \"corruption\", \"contamination\", \"pollution\", \"spillage\", \"overload\",\n",
        "    \"exhaustion\", \"depletion\", \"scarcity\", \"insufficiency\", \"lack\", \"absence\", \"deficit\", \"shortage\",\n",
        "    \"defectiveness\", \"fault\", \"imperfection\", \"vulnerability\", \"fragility\", \"breakability\", \"insecurity\",\n",
        "    \"exposure\", \"risk\", \"hazard\", \"danger\", \"peril\", \"threat\", \"jeopardy\", \"pitfall\", \"trap\", \"setback\",\n",
        "    \"problem\", \"difficulty\", \"concern\", \"worry\", \"anxiety\", \"stress\", \"tension\", \"pressure\", \"strain\",\n",
        "    \"burden\", \"weight\", \"load\", \"fatigue\", \"exhaustion\", \"weariness\", \"burnout\", \"discomfort\", \"pain\",\n",
        "    \"agony\", \"suffering\", \"misery\", \"torment\", \"distress\", \"affliction\", \"trouble\", \"crisis\", \"catastrophe\",\n",
        "    \"disaster\", \"calamity\", \"tragedy\", \"devastation\", \"chaos\", \"turmoil\", \"havoc\", \"pandemonium\", \"disarray\",\n",
        "    \"confusion\", \"disorganization\", \"disorder\", \"mess\", \"clutter\", \"complication\", \"misunderstanding\",\n",
        "    \"miscommunication\", \"misinterpretation\", \"conflict\", \"disagreement\", \"dispute\", \"argument\", \"quarrel\",\n",
        "    \"fight\", \"hostility\", \"resentment\", \"bitterness\", \"anger\", \"rage\", \"fury\", \"outrage\", \"wrath\", \"hatred\",\n",
        "    \"animosity\", \"antagonism\", \"loathing\", \"disgust\", \"repulsion\", \"revulsion\", \"negativity\", \"pessimism\",\n",
        "    \"cynicism\", \"skepticism\", \"doubt\", \"uncertainty\", \"apprehension\", \"fear\", \"dread\", \"terror\", \"horror\",\n",
        "    \"paranoia\", \"shock\", \"surprise\", \"unpleasantness\", \"offense\", \"insult\", \"humiliation\", \"shame\",\n",
        "    \"embarrassment\", \"awkwardness\", \"guilt\", \"remorse\", \"regret\", \"disappointment\", \"frustration\",\n",
        "    \"exasperation\", \"displeasure\", \"dissatisfaction\", \"discontent\", \"envy\", \"jealousy\", \"greed\", \"selfishness\",\n",
        "    \"arrogance\", \"pride\", \"egotism\", \"narcissism\", \"vanity\", \"superiority\", \"condescension\", \"rudeness\",\n",
        "    \"disrespect\", \"insensitivity\", \"inconsideration\", \"carelessness\", \"negligence\", \"recklessness\",\n",
        "    \"irresponsibility\", \"indifference\", \"apathy\", \"coldness\", \"harshness\", \"cruelty\", \"violence\", \"aggression\",\n",
        "    \"brutality\", \"oppression\", \"exploitation\", \"manipulation\", \"deception\", \"dishonesty\", \"betrayal\", \"fraud\",\n",
        "    \"corruption\", \"scandal\", \"crime\", \"theft\", \"robbery\", \"violence\", \"assault\", \"murder\", \"homicide\", \"abuse\",\n",
        "    \"harassment\", \"bullying\", \"discrimination\", \"prejudice\", \"bigotry\", \"injustice\", \"inequality\", \"suppression\",\n",
        "    \"censorship\", \"dictatorship\", \"tyranny\", \"war\", \"battle\", \"invasion\", \"occupation\", \"subjugation\", \"enslavement\",\n",
        "    \"poverty\", \"homelessness\", \"starvation\", \"malnutrition\", \"sickness\", \"disease\", \"illness\", \"infection\",\n",
        "    \"epidemic\", \"pandemic\", \"injury\", \"wound\", \"disability\", \"handicap\", \"impairment\", \"aging\", \"decline\",\n",
        "    \"depression\", \"melancholy\", \"sadness\", \"grief\", \"mourning\", \"loss\", \"loneliness\", \"isolation\", \"alienation\",\n",
        "    \"rejection\", \"abandonment\", \"neglect\", \"despair\", \"hopelessness\", \"worthlessness\", \"uselessness\",\n",
        "    \"destruction\", \"wreckage\", \"damage\", \"harm\", \"suffering\", \"torture\", \"persecution\", \"mercilessness\",\n",
        "    \"unfairness\", \"bias\", \"segregation\", \"marginalization\", \"foolishness\", \"ignorance\", \"stupidity\",\n",
        "    \"incompetence\", \"ineptitude\", \"clumsiness\", \"misfortune\", \"bad luck\", \"curse\", \"doom\", \"futility\",\n",
        "    \"pointlessness\", \"meaninglessness\", \"emptiness\", \"anguish\", \"shock\", \"delusion\", \"nightmare\", \"drowning\",\n",
        "    \"drowning\", \"meltdown\", \"breakup\", \"ruin\", \"bankruptcy\", \"infestation\", \"parasite\", \"disgusting\",\n",
        "    \"obnoxious\", \"worthless\", \"useless\", \"insignificant\", \"unimportant\", \"fail\", \"fallacy\", \"rumor\",\n",
        "    \"depressed\", \"broken\", \"ruined\", \"hopeless\", \"wretched\", \"shattered\", \"blasted\", \"poison\", \"backstabbed\",\n",
        "    \"betrayed\", \"downfall\", \"crumbling\", \"abomination\", \"awful\", \"horrible\", \"dismal\", \"deplorable\", \"disgrace\",\n",
        "    \"disgust\", \"dire\", \"bleak\", \"desperate\", \"failing\", \"troublemaker\", \"villain\", \"cheater\", \"usurper\",\n",
        "    \"liar\", \"thief\", \"miscreant\", \"scoundrel\", \"crook\", \"tyrant\", \"traitor\", \"fraudster\", \"embezzler\",\n",
        "    \"backstabber\", \"charlatan\", \"manipulator\", \"exploiter\", \"phony\", \"deceiver\", \"two-faced\", \"schemer\",\n",
        "    \"dishonorable\", \"unethical\", \"immoral\", \"sinister\", \"malicious\", \"nefarious\", \"vicious\", \"corrupt\",\n",
        "    \"insidious\", \"depraved\", \"diabolical\", \"malevolent\", \"villainous\", \"atrocious\", \"abysmal\", \"barbaric\",\n",
        "    \"heinous\", \"ghastly\", \"gruesome\", \"nightmarish\", \"demonic\", \"satanic\", \"fiendish\", \"morbid\", \"grisly\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "features = text_to_features(texts, positive_words, negative_words)\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "train_predictions = quantum_nearest_neighbor(train_features, train_labels, train_features)\n",
        "test_predictions = quantum_nearest_neighbor(train_features, train_labels, test_features)\n",
        "\n",
        "overall_predictions = np.concatenate((train_predictions, test_predictions))\n",
        "overall_labels = np.concatenate((train_labels, test_labels))\n",
        "\n",
        "overall_accuracy = np.mean(overall_predictions == overall_labels)\n",
        "print(f\"Overall Accuracy (Quantum-Inspired): {overall_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# (Keep the positive_words and negative_words lists as they are)\n",
        "\n",
        "# Define quantum device\n",
        "dev = qml.device(\"default.qubit\", wires=2, shots=1024)\n",
        "\n",
        "# Quantum feature extraction function\n",
        "@qml.qnode(dev)\n",
        "def quantum_embedding(inputs):\n",
        "    qml.AngleEmbedding(inputs, wires=[0, 1])\n",
        "    return qml.probs(wires=[0, 1])\n",
        "\n",
        "def text_to_features_single_word(word, positive_words, negative_words):\n",
        "    positive_count = 1 if word in positive_words else 0\n",
        "    negative_count = 1 if word in negative_words else 0\n",
        "    return np.array([positive_count, negative_count])\n",
        "\n",
        "def create_single_word_training_data(positive_words, negative_words):\n",
        "    texts = positive_words + negative_words\n",
        "    labels = [1] * len(positive_words) + [0] * len(negative_words)\n",
        "    features = [text_to_features_single_word(word, positive_words, negative_words) for word in texts]\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "def predict_word_sentiment(word, train_features, train_labels):\n",
        "    word_feature = text_to_features_single_word(word, positive_words, negative_words)\n",
        "    word_embedding = quantum_embedding(word_feature)\n",
        "\n",
        "    distances = [np.linalg.norm(word_embedding - emb) for emb in [quantum_embedding(f) for f in train_features]]\n",
        "    nearest_neighbor_index = np.argmin(distances)\n",
        "    predicted_label = train_labels[nearest_neighbor_index]\n",
        "\n",
        "    return \"Positive\" if predicted_label == 1 else \"Negative\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_features_single, train_labels_single = create_single_word_training_data(positive_words, negative_words)\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"Enter a sentence (or 'quit' to exit): \")\n",
        "        if user_input.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        if user_input:\n",
        "            words = user_input.split()\n",
        "            for word in words:\n",
        "                sentiment = predict_word_sentiment(word, train_features_single, train_labels_single)\n",
        "                print(f\"Sentiment of '{word}': {sentiment}\")\n",
        "        else:\n",
        "            print(\"Please enter a sentence.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU6Q_UMTEOER",
        "outputId": "bee3dc99-f722-4c00-a4eb-1d671f156a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence (or 'quit' to exit): good movie\n",
            "Sentiment of 'good': Positive\n",
            "Sentiment of 'movie': Positive\n",
            "Enter a sentence (or 'quit' to exit): don,t mess\n",
            "Sentiment of 'don,t': Negative\n",
            "Sentiment of 'mess': Negative\n",
            "Enter a sentence (or 'quit' to exit): quit\n"
          ]
        }
      ]
    }
  ]
}